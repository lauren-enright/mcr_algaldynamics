---
title: "MCR_Algae_Data_Cleaning"
author: "Noam Altman-Kurosaki and Lauren Enright"
date: "2024-05-03"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

rm(list=ls()) # clean up
library(knitr)
library(dplyr)
library(plyr)
library(car)
library(reshape)
library(reshape2)
library(tidyr)
library(effects)
library(devtools)
opts_chunk$set(comment="  ",
               collapse=TRUE, 
               echo=FALSE,
               #fig.asp=1/gr,
               fig.height=8,
               fig.width = 10,
               dev="png",
               warning=TRUE
               )
opts_knit$set(eval.after = "fig.cap") 

```

```{r data cleaning}
library(here)

data <- read.csv(here("data", "MCR_LTER_Annual_Survey_Benthic_Cover_20231211.csv"), stringsAsFactors = F) # replacements don't work when strings are factors
str(data)
levels(as.factor(data$Taxonomy_Substrate_Functional_Group)) # 86 levels
data$Site_habitat <- as.factor( paste(data$Site, data$Habitat))

#### REPLACE OUTDATED TAXA

# Caulerpa peltata is outdated --> Caulerpa racemosa
data$Taxonomy_Substrate_Functional_Group[data$Taxonomy_Substrate_Functional_Group == "Caulerpa peltata"] <- "Caulerpa racemosa"

# Boodlea kaeneana --> Cladophoropsis membranacea
data$Taxonomy_Substrate_Functional_Group[data$Taxonomy_Substrate_Functional_Group == "Boodlea kaeneana"] <- 
  "Cladophoropsis membranacea"

# Cladophoropsis luxurians --> Cladophora fuliginosa
data$Taxonomy_Substrate_Functional_Group[data$Taxonomy_Substrate_Functional_Group == "Cladophoropsis luxurians"] <-
  "Cladophora fuliginosa"

# Neogoniolithon frutescens --> Neogoniolithon brassica-florida
data$Taxonomy_Substrate_Functional_Group[data$Taxonomy_Substrate_Functional_Group == "Neogoniolithon frutescens"] <- 
  "Neogoniolithon brassica-florida"

# remove old levels
data <- droplevels(data)
levels(as.factor(data$Taxonomy_Substrate_Functional_Group)) # 84 levels

```

```{r QA QC - checking quadrats}

quad_level_summary <- data %>%
  dplyr::group_by(Year, Location, Site, Habitat, Site_habitat, Transect, Quadrat) %>%
  dplyr::summarize(sum = sum(Percent_Cover))

non100_quad_level <- quad_level_summary %>%
  dplyr::filter(sum != 100)

#99 observations that do not equal 100

#how many are no data (-1)
quad_level_summary %>%
  dplyr::filter(sum == -1)

#14

mistakes_quad_level <- quad_level_summary %>%
  dplyr::filter(sum != 100) %>%
  dplyr::filter(sum != -1)

#remaining 85 have something weird happening! Will send to Bob for updates. For now, 
# will filter these out

unique(quad_level_summary$sum)

#write out these 85 

#write.csv(mistakes_quad_level, "mistakes_quad_level.csv", row.names = FALSE)
```

```{r subsetting the data }

### CREATE DATAFRAME THAT IS JUST ALGAE

not_algae <- c("Ascidian", "Bare Space", "Coral", "Coral Rubble", "Corallimorpharia", "Heteractis sp.", "Millepora platyphylla", "No data", "Sand", "Sacrophyton sp.", "Shell Debris", "Soft Coral", "Sponge", "Tridacna sp.", "Zooxanthellae")

### CREATE DATAFRAME THAT IS JUST MACROALGAE
# Maintaining mat-forming cyanos even though they're not macroalgae in the traditional sense
# "Coelothrix irregularis", "Symploca hydnoides" 

not_macro <- c("Algal Turf", "Crustose Corallines", "Cyanophyta", "Damselfish Turf", "Lithophyllum kotschyanum", "Neogoniolithon brassica-florida", "Sporolithon sp." )

```


```{r wide - with all data}

comb_wide <- cast(data, Year + Location + Site + Habitat + Site_habitat + Transect + Quadrat ~ Taxonomy_Substrate_Functional_Group, fun.aggregate = mean, value = "Percent_Cover") # this is the correct number of rows given the missing data

#change NAs to 0s 

is.nan.data.frame <- function(x){
  do.call(cbind, lapply(x, is.nan))}

comb_wide[is.nan.data.frame(comb_wide)] <- 0

```

```{r QAQC for the wide dataset}

comb_wide_quad_sum <- comb_wide %>%
  mutate(row_sums = rowSums(dplyr::select(., 8:91)))

#do we have data for all transects?

comb_wide_quad_sum %>%
  dplyr::group_by(Year, Site) %>%
  dplyr::summarise(count = n())

#should be 200 per year per site (50 at each habitat * 4 habitats)
#2005 and 2006 are one large collective survey
#2021 sites are at 100 (did not do forereef habitats due to COVID)

#do all quads = 100 ?

non100_wide_quad_level <- comb_wide_quad_sum %>%
  dplyr::filter(row_sums != 100)

#also 99 observations that do not equal 100

#how many are no data (-1)
comb_wide_quad_sum %>%
  dplyr::filter(row_sums == -1)

#14

mistakes_wide_quad_level <- comb_wide_quad_sum %>%
  dplyr::filter(row_sums != 100) %>%
  dplyr::filter(row_sums != -1)

comb_wide_quad_sum %>%
 dplyr::filter(row_sums != 100) %>% dplyr::filter(Year == 2020)

#remaining 85 have something weird happening! Will send to Bob for updates. For now, 
# will filter these out

#want to make sure these 85 are the same we found using the long data

setdiff(mistakes_wide_quad_level$Location, mistakes_quad_level$Location)

setdiff(mistakes_quad_level$Location, mistakes_wide_quad_level$Location)

#yay, they are the same 85 


```
```{r}

test <- comb_wide_quad_sum %>%
  dplyr::group_by(Year, Site, Habitat, Transect) %>%
  dplyr::summarise(sum = sum(Quadrat))

test <- comb_wide_quad_sum %>%
  dplyr::group_by(Year, Site, Habitat) %>%
  dplyr::summarise(sum = sum(Transect))

test <- comb_wide_quad_sum %>%
  dplyr::group_by(Year, Site) %>%
  dplyr::summarise(count = n())


unique(test$sum)

test <- comb_wide_quad_sum %>%
  dplyr::group_by(Year) %>%
  dplyr::summarise(sum = sum(Transect))


test <- wide_alldata_filtered %>%
  dplyr::group_by(Year, Site, Habitat) %>%
  dplyr::summarise(count = n())

nique(comb_wide_quad_sum$Year)

sum(test$sum)

(1*10) + (2*10) + (3*10) + (4*10) + (5*10)

```


```{r filter the wide dataset}

#we want to filter out 2005 and 2006 - these were "ramp up years"
#also want to filter out rows where the sum does not = 0 
wide_alldata_filtered <- comb_wide_quad_sum %>%
  dplyr::filter(Year != 2005 & Year != 2006) %>%
  dplyr::filter(row_sums == 100)

write.csv(wide_alldata_filtered, "allbenthicdata_cleaned.csv", row.names = FALSE)

#we also want a copy that only includes taxa we care about 
#not_algae character string created by Noam in Chunk 4 (Subsetting the data) and includes 14 
#categories  -- these categories will be listed in a separate document as well 

wide_algaeonly_filtered <- wide_alldata_filtered[ , -which(names(wide_alldata_filtered) 
                                                           %in% not_algae)]

#need to still remove the row_sums column for algae only 

wide_algaeonly_filtered <- wide_algaeonly_filtered %>%
  dplyr::select(-row_sums)

write.csv(wide_algaeonly_filtered, "algaeonly_cleaned.csv", row.names = FALSE)

```

```{r filtered data QA QC}
# you can use this to see which sites lost quads during filtering process 
#should be 50 per year/site/habitat combo

wide_alldata_filtered %>%
  dplyr::group_by(Year, Site, Habitat) %>%
  dplyr::summarise(count = n())

wide_alldata_filtered %>%
  dplyr::group_by(Year, Site) %>%
  dplyr::summarise(count = n())

```


## Anything below this line was to help identify missing data, overall taxa levels, etc. and does not necessarily need to be run to get a cleaned dataframe 


```{r subsetting the data }

### CREATE DATAFRAME THAT IS JUST ALGAE
not_algae <- c("Ascidian", "Bare Space", "Coral", "Coral Rubble", "Corallimorpharia", "Heteractis sp.", "Millepora platyphylla", "No data", "Sand", "Sacrophyton sp.", "Shell Debris", "Soft Coral", "Sponge", "Tridacna sp.", "Zooxanthellae")

algae_df <- data[ ! data$Taxonomy_Substrate_Functional_Group %in% not_algae, ]
algae_df <- droplevels(algae_df)
levels(as.factor(algae_df$Taxonomy_Substrate_Functional_Group )) # 70 levels


### CREATE DATAFRAME THAT IS JUST MACROALGAE
# Maintaining mat-forming cyanos even though they're not macroalgae in the traditional sense
# "Coelothrix irregularis", "Symploca hydnoides" 
not_macro <- c("Algal Turf", "Crustose Corallines", "Cyanophyta", "Damselfish Turf", "Lithophyllum kotschyanum", "Neogoniolithon brassica-florida", "Sporolithon sp." )

macro_df <- algae_df[! algae_df$Taxonomy_Substrate_Functional_Group %in% not_macro, ]
macro_df <- droplevels(macro_df)
levels(as.factor(macro_df$Taxonomy_Substrate_Functional_Group )) # 63 levels

# NOTE: WHICH DO WE WANT TO WORK WITH?
# MY VOTE IS "algae_df"

```


```{r create wide df - algae only}
# using algae data
# I don't think the date of the transect matters. Dropping that.

algae_wide <- cast(algae_df, Year + Location + Site + Habitat + Site_habitat + Transect + Quadrat ~ Taxonomy_Substrate_Functional_Group, fun.aggregate = mean, value = "Percent_Cover")
# replace NaN in dataframe
# function from https://stackoverflow.com/questions/18142117/how-to-replace-nan-value-with-zero-in-a-huge-data-frame

is.nan.data.frame <- function(x){
  do.call(cbind, lapply(x, is.nan))}

algae_wide[is.nan.data.frame(algae_wide)] <- 0

length(levels(as.factor(algae_wide$Year))) # 19 years of data collection
length(levels(algae_wide$Site_habitat)) # 24 sites
# 5 transects and 10 quads per transect
# should be 22800 rows, so clearly some years are missing sites

```

```{r missing data part 1}

### NOTE - USED CHAT GPT FOR THIS NEXT PART
# Step 1: Create a contingency table of counts for each combination of year and site
year_site_counts <- table(comb_wide$Year, comb_wide$Site_habitat)

# Step 2: Identify rows with zero counts (indicating missing sites)
missing_years <- rownames(year_site_counts)[rowSums(year_site_counts == 0) > 0] # 2005, 2006, 2021 missing data

# should be 19200 rows if we remove those years
nrow(algae_wide[! algae_wide$Year %in% missing_years,]) # 19186... what are those 14 datapoints??

# Step 3: Extract the years corresponding to missing sites
for (year in missing_years) {
  # Filter the dataframe for the current missing year
  missing_year_data <- subset(algae_wide, Year == year)
  
  # Get the unique sites present in the missing year data
  present_sites <- unique(missing_year_data$Site_habitat)
  
  # Get all possible sites
  all_sites <- unique(algae_wide$Site_habitat)
  
  # Identify missing sites
  missing_sites <- setdiff(all_sites, present_sites)
  
  # Print missing sites for the current year
  cat("Year", year, "is missing data from sites:", paste(missing_sites, collapse = ", "), "\n")
}

# try to find what else is missing
algae_subset <- algae_wide[! algae_wide$Year %in% missing_years,]

site_transect_counts <- table(algae_subset$Site_habitat, algae_subset$Transect)
site_quadrat_counts <- table(algae_subset$Site_habitat, algae_subset$Quadrat)

# Step 2: Identify sites with missing transects or quadrats
missing_transect_sites <- rownames(site_transect_counts)[rowSums(site_transect_counts == 0) > 0]
missing_quadrat_sites <- rownames(site_quadrat_counts)[rowSums(site_quadrat_counts == 0) > 0]

# Step 3: Print out sites with missing transects or quadrats
print(paste("Sites with missing transects:", missing_transect_sites))
print(paste("Sites with missing quadrats:", missing_quadrat_sites))
 # Hm, nothing missing
```

```{r missing data part 2}
# create a dataframe with all possible combinations of year, site, habitat, transect, quadrat
year <- unique(data$Year)
sites <- unique(data$Site)
habitat <- unique(data$Habitat)
transect <- unique(data$Transect)
quadrat <- unique(data$Quadrat)
all_comb <- expand_grid(year, sites, habitat, transect, quadrat)
all_comb$comb <- paste(all_comb$year, all_comb$sites, all_comb$habitat, all_comb$transect, all_comb$quadrat)

# create a vector with the combinations that are actually present in the data
data$comb <- paste(data$Year, data$Site, data$Habitat, data$Transect, data$Quadrat) 
data_comb <- unique(data$comb) 

missing_quadrats <- setdiff(all_comb$comb, data_comb)
length(missing_quadrats) # 1800 missing quadrats, consistent with the missing sites/years above
# extra missing values might be from quadrats with no algae in wide dataframe?

```


